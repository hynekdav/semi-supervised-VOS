Loss function: modified cross-entropy to work with similarity matrix. It works as follows:
    1. gets pixel-level similarity matrix by batch matrix-matrix product from batches of reference and target pixels
    2. softmax of the calculated similarity matrix
    3. matrix-matrix product of the reference annotation and the similarity matrix
    4. feeding the product into logarithm and into the negative log loss

Model: First 8 layers of ResNet without any special modifications, pretrained on ImageNet.
The training itself works as follows:
    1. each annotation image gets downsampled by factor of 0.125
    2. each pixel of annotation gets assigned a class
    3. normalized image is put through the model to get the features
    4. predicted features, target features, predicted annotation and target annotation are then sent into the loss
